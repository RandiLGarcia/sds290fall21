---
title: "SDS 290 Homework 6"
output:
  html_document:
    theme: cerulean
    highlight: pygments
    css: lab.css
    toc: true
    toc_float: true
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(eval = FALSE)
library(dplyr)
library(ggplot2)
library(tidyr)
#library(oilabs)
library(mosaic)
```

### R Packages

R is an open-source programming language, meaning that users can contribute
packages that make our lives easier, and we can use them for free. In this homework,
and many others in the future, we will use the following R packages:

- `dplyr`: for data wrangling
- `ggplot2`: for data visualization
- `mosaic`: for basic statistical computing

You need to load these packages in your working environment. We do this with
the `library()` function. Run the following three lines in your console.

```{r load-packages, message = FALSE, eval=TRUE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(mosaic)
```

Note that you only need to *load* then with the `library()` 
function each time you relaunch RStudio. 

***

## One-Way Basic Factorial Design

Let us start with the BF[1] example of plant trampling. Deputy director of the Pawnee Parks and Rec department, Leslie Knope, needs to know how resistant different vegetative types are to trampling so that the number of visitors can be controlled in sensitive areas. Twenty lanes of a park are established, each .5 m wide and 1.5 m long. These twenty lanes are randomly assigned to five treatments: 0, 25, 75, 200, or 500 walking passes. Each pass consists of a 70-kg individual wearing boots, walking in a natural gait. One year after trampling, the average height of the vegetation along the lanes are measured. The data from this experiment is entered into a data frame using the code below. 

```{r}
parks <- data.frame(passes = c(rep("0", 4), rep("25", 4), 
                            rep("75", 4), rep("200", 4), 
                            rep("500", 4)), 
                    height = c(20.7, 15.9, 17.8, 17.6, 
                            12.9, 13.4, 12.7, 9.0, 
                            11.8, 12.6, 11.4, 12.1, 
                            7.6, 9.5, 9.9, 9.0, 
                            7.8, 9.0, 8.5, 6.7))
```

### Parallel Dot Graph

Using the `parks` data frame created from the code above, we can make a parallel dot graph using the `ggplot()` function from the `ggplot2` package. 

```{r}
ggplot(parks, aes(x = passes, y = height)) +
  geom_point()
```

What do you notice? For which treatment do the plants fair the best? We can also look at parallel dot graphs to get a sense of the validity of the S, same standard deviations, Fisher assumption. 

We can add the averages for each condition to the plot with an additional `geom_point()` layer. In this second `geom_point()` layer we add map the mean to the y aesthetic instead of the response variable. Note that we can compute the averages for each condition easily with `group_by()` and `mutate()`. 

```{r}
parks %>%
  group_by(passes) %>%
  mutate(mean = mean(height)) %>%
ggplot(aes(x = passes, y = height)) +
  geom_point() +
  geom_point(aes(y = mean), color = "mediumvioletred", size = 4, shape = 6)
```

### Formal ANOVA

If we feel comfortable with that assumption, we can move forward with the formal ANOVA for BF[1] design. We will use the `lm()` function and save this model in an object, here we name that object `mod`. Note that inside of the `lm()` function, the model is given as `response ~ factor` using the formula notation, `y ~ x`. The data is also given by typing `data = parks`. The formula and the data are *arguments* passed to the `lm()` function. Next, to get the ANOVA decomposition, F-ratios, and p-values for those F-ratios by passing the `anova()` function our `mod` object. 

```{r}
mod <- lm(height ~ passes, data = parks)

anova(mod)
```

What can we conclude about the effect of foot traffic, passes, on the height of plants?

### Residual Plot

After running our formal ANOVA, we should look at the model residuals to get a sense of how valid our N assumption is. 

```{r}
parks <- parks %>%
  mutate(residuals = residuals(mod),
         SD = sd(residuals))
```

Now that we have a variable saved in our data frame that contains the residuals, we can visualize these residuals with the `ggplot()` function. In a layer on top of our histogram, we want to add two vertical lines that cut off 1 SD above and below the mean (of zero). We can accomplish this with the `geom_vline()` function. The `v` stands for vertical. The `geom_vline()` function needs to know the `xintercept` aesthetic to know where to draw the line. We'll make these lines blue by adding the `color = "blue"` argument to `geom_vline()`. 

```{r}
ggplot(parks, aes(x = residuals)) +
  geom_histogram(bins = 10) +
  geom_vline(aes(xintercept = SD), color = "blue") +
  geom_vline(aes(xintercept = -SD), color = "blue")
```

<!-- ## Two-Way Basic Factorial Design -->

## Creating a Data Frame in R

To create a data frame for data from a bf[1] design, we will want two variables: 1) the response variable observations and 2) the level for each observation of the factor. 

The code below creates a data frame for the leafhopper data (p. 169). First, notice that observations on the response variable, `days` are specified inside of the `c()` function. The `c` stands for concatenate, and this concatenate function makes lists in R. Next, levels of the `diet` variable are created, again with the `c()` function, but also making use of the `rep()` function. The `rep()` function will repeat the first argument how ever many times you specify in the second argument. 

```{r}
days <- c(2.3, 1.7, 3.6, 4.0, 2.9, 2.7, 2.1, 2.3)
diet <- c(rep("control", 2), rep("sucrose", 2), rep("glucose", 2), rep("fructose", 2))
```

Right now these two variables are just lists of information that are unrelated to each other.

Finally, to relate the variables to each other, both variables are contain in a data frame with the `data.frame()` function, and the data frame is saved in an object called `leaf`. A data frame is a list of lists!

```{r}
leaf <- data.frame(days, diet)
```

Take a look at the data frame with the `View()` function.

```{r}
View(leaf)
```

<!-- piglets <- data.frame(gain = c(1.3, 1.19, 1.08,  -->
<!--                                1.05, 1.0, 1.04, -->
<!--                                1.26, 1.21, 1.19, -->
<!--                                1.52, 1.56, 1.54),  -->
<!--                       antibiotic = c(rep("0mg", 3), rep("40mg", 3), rep("0mg", 3), rep("40mg", 3)), -->
<!--                       B12 = c(rep("0mg", 6), rep("5mg", 6))) -->

<!-- ### Explore the Data -->

<!-- First we get the cell averages. Note that for whichever variable you list after the `|`, you will get overall means by group. -->

<!-- ```{r} -->
<!-- favstats(gain ~ B12|antibiotic, data = piglets) -->
<!-- ``` -->

<!-- ### Informal Analysis -->

<!-- Then we look at it visually, creating a parallel dot graph for piglets data. -->

<!-- ```{r} -->
<!-- ggplot(piglets, aes(x = B12, y = gain, shape = antibiotic, color = antibiotic)) + -->
<!--   geom_point(size = 2) -->
<!-- ``` -->

<!-- Or a parallel boxplot. -->

<!-- ```{r} -->
<!-- ggplot(piglets, aes(x = B12, color = antibiotic, y = gain)) +  -->
<!--   geom_boxplot() -->
<!-- ``` -->

<!-- ### Interaction Graph -->

<!-- Finally, beacuse this is a bf[2] design, we will want to check for an interaction between factor 1 and factor 2. We can create an interaction graph starting with the same code above for the parallel dot graph. We will add a few more aesthetics to the `ggplot()` function including `group = antibiotic` and `linetype = antibiotic`. Once we have added these two aesthetics, we can add a new layer to the plot that will connect the means for each B12 group within each level of antibiotic. We do this with the `geom_smooth(method = "lm", se = 0)` code.  -->

<!-- ```{r} -->
<!-- ggplot(piglets, aes(x = B12, y = new_gain, shape = antibiotic, color = antibiotic, -->
<!--                     group = antibiotic,  -->
<!--                     linetype = antibiotic)) + -->
<!--   geom_point(size = 2) + -->
<!--   geom_smooth(method = "lm", se = 0) -->
<!-- ``` -->

<!-- ### Bonus: Formal ANOVA -->

<!-- We can also conduct a formal two-way ANOVA for this bf[2] data using the code below. Note the `antibiotic * B12` in the formula. This gives us F-ratios for the two main effects as well as the interaction.  -->

<!-- ```{r} -->
<!-- mod2 <- lm(gain ~ antibiotic * B12, data = piglets) -->

<!-- anova(mod2) -->
<!-- ``` -->

***

## Homework 6 Problems

For homework 6, complete the following exercises. When you are done, please knit your 
homework to an HTML file and submit the HTML file on Moodle.

Refer to the walking babies example on page 150 of your textbook for exercises 1-3. For exercises 1-3, you will be conducting an analysis to test if there are differences in age in months when babies first walked depending on the group they were assigned to. 

```{r, include=FALSE}
special <- c(9, 9.5, 9.75, 10, 13, 9.5)
control1 <- c(11, 10, 10, 11.75, 10.5, 15)
control2 <- c(11, 12, 9, 11.5, 13.25, 13)
control3 <- c(13.25, 11.5, 12, 13.5, 11.5, 12.5)

walking <- data.frame(special, control1, control2, control3) %>%
  gather(group, age, special:control3)
```

1. Using the method describe above for the leafhopper data, create a data frame in your R Studio environment called `walking` with the data given in Table 5.1 on page 150 of your textbook. What kind of design is this? 

1. Create a parallel dot graph of the walking data. What do you notice? Also, using `favstats()`, check the standard deviations between groups (the S assumption). Is the largest SD >3 times as large as the smallest?

```{r, include = FALSE}
ggplot(walking, aes(x = group, y = age)) +
  geom_point()
```

```{r, include = FALSE}
favstats(age ~ group, data = walking)

1.90/0.86
```

2. Conduct an ANOVA to test the research question: Do special exercises speed up the process of babies learning to walk? What do you conclude about these baby exercise programs from your ANOVA? 

```{r, include = FALSE}
mod <- lm(age ~ group, data = walking)

anova(mod)
```

3. Make a histogram of residuals for the model you ran in exercise 2, complete with `vlines` marking 1 SD above and below the mean. Using this histogram, discuss the validity of the N and Z assumptions. 

```{r, include = FALSE}
walking <- walking %>%
  mutate(residuals = residuals(mod),
         SD = sd(residuals))

ggplot(walking, aes(x = residuals)) +
  geom_histogram(bins = 10) +
  geom_vline(aes(xintercept = SD), color = "blue") +
  geom_vline(aes(xintercept = -SD), color = "blue")
```


<!-- Refer to the hornworm example on page 208 (problems 1 and 7) of your textbook for exercises 4-5.  -->

<!-- 4. Create a data frame in your R Studio environment called `hornworms` with the data given in problem 7 on page 209 of your textbook. For help, review the discussion above on how the `piglet` data was entered. What are the units for this data frame? How many observations are there? -->

<!-- ```{r, include=FALSE} -->
<!-- hornworms <- data.frame(consumption = c(43, 61, 45, 35, 31, 31, -->
<!--                                         105, 90, 104, 107, 123, 113, -->
<!--                                         41, 39, 38, 36, 41, 27, -->
<!--                                         103, 109, 100, 110, 118, 90), -->
<!--                         diet1 = c(rep("regular", 12), rep("cellulose", 12)), -->
<!--                         diet2 = c(rep("regular", 6), rep("cellulose", 6), rep("regular", 6), rep("cellulose", 6))) -->
<!-- ``` -->


<!-- 5. Using the data you created in exercise 4, create an interaction graph. Refer to the interaction graph code for the `piglet` example above. based on your graph, is there a main effect of the first diet? Is there a main effect of the second diet? Is there an interaction of the diet given first and the diet given second? -->

<!-- ```{r, include=FALSE} -->
<!-- ggplot(hornworms, aes(x = diet1, y = consumption, shape = diet2, color = diet2, -->
<!--                     group = diet2,  -->
<!--                     linetype = diet2)) + -->
<!--   geom_point(size = 2) + -->
<!--   geom_smooth(method = "lm", se = 0) -->
<!-- ``` -->

4. Create a data frame in your R Studio environment called `fluids` with the data given in Table 5.2 on page 153 of your textbook. For help, review the discussion above on how the `leaf` data was entered. What are the units for this data frame? How many observations are there?

5. Conduct an ANOVA on this data set, complete with a parallel dot graph and making sure to check your residual assumptions along the way. What do you conclude about the purity of intravenous fluids across these three drug companies? 

<div id="license">
This is a product of OpenIntro that is released under a 
[Creative Commons Attribution-ShareAlike 3.0 Unported](http://creativecommons.org/licenses/by-sa/3.0). 
This lab was adapted by Randi Garcia from labs originally written by Mark Hansen, further 
adapted for OpenIntro by Andrew Bray and Mine &Ccedil;etinkaya-Rundel.
</div>

* * *

## Resources for learning R and working in RStudio

That was a short introduction to R and RStudio, but we will provide you with more
functions and a more complete sense of the language as the course progresses. 

In this course we will be using R packages called `dplyr` for data wrangling 
and `ggplot2` for data visualization. If you are googling for R code, make sure
to also include these package names in your search query. For example, instead
of googling "scatterplot in R", google "scatterplot in R with ggplot2".

These cheatsheets may come in handy throughout the semester:

- [RMarkdown cheatsheet](https://www.rstudio.com/wp-content/uploads/2016/03/rmarkdown-cheatsheet-2.0.pdf)
- [Data wrangling cheatsheet](http://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)
- [Data visualization cheatsheet](http://www.rstudio.com/wp-content/uploads/2015/12/ggplot2-cheatsheet-2.0.pdf)

Chester Ismay has put together a resource for new users of R, RStudio, and R Markdown
[here](https://ismayc.github.io/rbasics-book).  It includes examples showing working with R Markdown files
in RStudio recorded as GIFs.

Note that some of the code on these cheatsheets may be too advanced for this course,
however majority of it will become useful throughout the semester.