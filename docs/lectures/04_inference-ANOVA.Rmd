---
title: "Inference for ANOVA"
author: "SDS 290"
date: "September 14, 2021"
output: 
  ioslides_presentation:
    widescreen: true
    smaller: true
---


## Announcements

- Grades are posted for HW1a, HW1b, and HW1c
    - Solution sheet will be avaliable on Moodle on Wed
- HW2 posted    
- In-person Office hours (Bass 412)
    - Wed 10:50-12:05p
    - Thurs 1:20-2:35p
    - or by appointment!
- Zoom Office hours
    - Full for this week!
- Where to get HW help
    - [Spinelli center](https://www.smith.edu/qlc/tutoring.html) tutoring Sun-Thurs 7-9p, Sabin-Reed 301.
- SDS Lounge study space McConnell 209    

## Leafhopper survival

One-Way Design

It is reasonable to assume that the structure of a sugar molecule has something to do with its food value.
An experiment was conducted to compare the effects of four sugar diets on the survival of leafhoppers. The four diets were glucose and fructose (6-carbon atoms), sucrose (12-carbon), and a control (2% agar). The experimenter prepared two dishes with each diet, divided the leafhoppers into eight groups of equal size, and then randomly assigned them to dishes. Then she counted the number of days until half the insects had died in each group.

## Decomposing the data

```{r, echo = FALSE, message=FALSE, warning=FALSE}
library(knitr)
library(tidyverse)
library(mosaic)

kable(data.frame(control = c(2.3,1.7), sucrose = c(3.6, 4.0), glucose = c(2.9,2.7), fructose = c(2.1,2.3)))
```

- Let's draw a factor diagram, including a place for the grand mean and residuals.

## Leafhoppers

Bar graph of treatment condition averages. 

```{r, echo=FALSE}
leaf <- data.frame(diet = c("control","control","sucrose", "sucrose", "glucose", "glucose", "fructose","fructose"), days = c(2.3,1.7,3.6,4.0,2.9,2.7,2.1,2.3))
leaf %>%
  group_by(diet) %>%
  summarise(means = mean(days)) %>%
  mutate(bench = mean(means)) %>%
ggplot(aes(x = diet, y = means)) +
  geom_bar(stat = "identity") +
  geom_hline(aes(yintercept = bench), color = "red") 


leaf <- leaf %>%
  mutate(benchmark = mean(days)) %>%
  group_by(diet) %>%
  mutate(grp_mean = mean(days),
         diet_effect = grp_mean - benchmark) %>%
  ungroup() %>%
  mutate(fitted = benchmark + diet_effect,
         resid = days - grp_mean,
         resid_alt = days - fitted)
```

## Leafhoppers

- We'll now start thinking about if those differences in treatment effects are real, or could possibly be due to chance error. 
- To the factor diagram, let's add in the grand mean, the effects for diet, and the residuals

```{r, echo = FALSE}
kable(data.frame(' ' = c("","","means"), control = c(2.3,1.7, 2.0), sucrose = c(3.6, 4.0, 3.8), glucose = c(2.9,2.7,2.8), fructose = c(2.1,2.3,2.2)))
```

## One-way ANOVA Model

$$Y = f(X) + \epsilon$$
For t-test our model is:
$$Y = \mu_i + \epsilon$$
For One-Way ANOVA our model is:
$$Y = \mu + \alpha_i + \epsilon$$
where $\mu$ is the grand mean, $\alpha_i$ is the treatment effect (difference from the grand mean for the $i^{th}$ group), and $\epsilon$ is the residual. 

### Note about using SLR for categorical variables

When we have a binary explanatory variable, X, where X is an indicator of category 2:

$$Y = \beta_0+\beta_1X_{indicator}+\epsilon$$
where $\beta_0$ is the mean of category 1, and $\beta_1$ is the difference between the mean of category 1 and the mean of category 2.

## Analysis of Variance ANOVA

Formal ANOVA starts with the simple idea that we can compare our estimate of **treatment effect variability** to our estimate of **chance error variability** to measure how large our treatment effect is. 
&nbsp;  
$$Variability\:in\:Treatment\:E\mathit{f}\mathit{f}ects = True\:E\mathit{f}\mathit{f}ect\:Di\mathit{f}\mathit{f}erences + Error$$
$$Variability\:in\:Residuals = Error$$
&nbsp;  
We can construct a comparison, which we will call F:
&nbsp;  
$$F = \frac{Variability\:in\:Treatment\:E\mathit{f}\mathit{f}ects}{Variability\:in\:Residuals}=\frac{True\:E\mathit{f}\mathit{f}ect\:Di\mathit{f}\mathit{f}erences + Error}{Error}$$
&nbsp;  
If our null hypothesis, ${H}_{0}: True\:E\mathit{f}\mathit{f}ect\:Di\mathit{f}\mathit{f}erences=0$, is true, then what would we expect the F-ratio to equal?


## Sum of Squares (SS)

ANOVA measures variability in treatment effects with the sum of squares ($SS$) divided by the number of units of unique information ($df$). For the One-Way design:

$${SS}_{Treatments} = n\sum_{i=1}^{a}(\bar{y}_{i.}-\bar{y}_{..})^{2}$$

$${SS}_{E} = \sum_{i=1}^{a}\sum_{j=1}^{n}({y}_{ij}-\bar{y}_{i.})^{2}$$

$${SS}_{Total} = {SS}_{Treatments} + {SS}_{E}$$

where $n$ is the group size, and $a$ is the number of treatments.

## Degrees of Freedom (df)

The $df$ for a table equals the number of free numbers, the number of slots in the table you can fill in before the pattern of repetitions and adding to zero tell you what the remaining numbers have to be. 

$${df}_{Treatments}=a-1$$

$${df}_{E}=N-a$$

## Mean Squares (MS)

The ultimate statistic we want to calculate is $F = \frac{Variability\:in\:Treatment\:E\mathit{f}\mathit{f}ects}{Variability\:in\:Residuals}$.

**Variability in treatment effects**:
$${MS}_{Treatments}=\frac{{SS}_{Treatments}}{{df}_{Treatments}}$$

**Variability in residuals**
$${MS}_{E}=\frac{{SS}_{E}}{{df}_{E}}$$


## F-ratios and the F-distribution

Finally, the ratio of these two MS's is called the F ratio. The following quantity is our test statistic for the null hypothesis that there are no treatment effects.

$$F = \frac{{MS}_{Treatments}}{{MS}_{E}}$$

If the null hypothesis is true, then F is a random variable $\sim F({df}_{Treatments}, {df}_{E})$. The [F-distribution](https://en.wikipedia.org/wiki/F-distribution).

```{r, eval=FALSE}
qplot(x = rf(500, 3, 4), geom = "density")
```

## Inference Testing in ANOVA

$${H}_{0}:\mu_1=\mu_2=\mu_3=\mu_4$$

*OR*, ${H}_{0}:\alpha_1=\alpha_2=\alpha_3=\alpha_4=0$

$${H}_{A}:some\:\mu_i\neq\mu_j$$

Or $H_a: Some\:\alpha_i\neq 0$. We can find the p-value for our F calculation with the following code

```{r, eval=FALSE}

pf(17.422, 3, 4, lower.tail = FALSE)
```

## ANOVA Source Table

```{r}
mod <- lm(days ~ diet, data = leaf)
anova(mod)
```


<!-- DO FULL ANOVA TABLE ON BOARD FOR LEAFHOPPERS -->

## ANOVA Conditions

But only under certain conditions can we rely on this inference.

### Simulation in R: Assembly Line Metaphor

![](https://thumbs.gfycat.com/MelodicCalculatingBluejay.webp)

- Recall the [Assembly Line Metaphor code](https://randilgarcia.github.io/sds290fall21/lectures/02_informal_anova.Rmd)

## ANOVA Conditions

![](04_exp_decisions-figure/CA-SINZ2.png)

- C. Constant effects
- A. Additive effects
- S. Same standard deviations
- I. Independent residuals
- N. Normally distributed residuals
- Z. Zero mean residuals

## C. Constant effects

We assume every observation in a similar condition is affected exactly the same. (Gets the same "true score").

```{r, eval=FALSE}
animals_sim <- animals %>%
  mutate(benchmark = mean(calm)) %>%
  group_by(animal) %>%
  mutate(animal_mean = mean(calm),
         aminal_effect = animal_mean - benchmark)
```

## A. Additive effects

We add the effects as we go down the assembly line.

The interaction effect captures the possibility that conditions have non-additive effects, but it is also added to everything else.

```{r, eval=FALSE}
calm_sim = benchmark
         + aminal_effect
         + cue_effect
         + interaction_effect
         + student_effect
```

## S. Same standard deviations

The peice of code for adding error is not dependent on which condition the observations is in.

```{r, eval=FALSE}
 + rnorm(82, 0, 0.79)
```

## I. Independent residuals

Takes 82 independent draws from a normal distribution.

```{r, eval=FALSE}
 + rnorm(82, 0, 0.79)
```

## N. Normally distributed residuals

It's `rnorm()`, and not `rbinom()` or `rpois()`...

```{r, eval=FALSE}
 + rnorm(82, 0, 0.79)
```

## Z. Zero mean residuals

The second argument is the mean.

```{r, eval=FALSE}
 + rnorm(82, 0, 0.79)
```

## ANOVA in R

- Analyzing the leafhopper data in R. [code here](https://randilgarcia.github.io/sds290fall21/lectures/05_formal_anova.Rmd)
